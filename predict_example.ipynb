{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Concatenate as concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Flatten, Dropout, Dense, Input\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn import metrics\n",
    "import gensim\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "import logging\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.layers import Flatten, Layer, InputSpec\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)s: %(message)s', \n",
    "                    level=logging.INFO, \n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 3000\n",
    "tokenizer = pickle.load(open(\"../tmp_data/textcnn_maxlen3000_tokenizer.pickle\", \"rb\"))\n",
    "vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 17:48:43 INFO: loading Word2Vec object from ../tmp_data/word2vec.d300.sg.w5.model\n",
      "2020-09-08 17:48:44 INFO: loading wv recursively from ../tmp_data/word2vec.d300.sg.w5.model.wv.* with mmap=None\n",
      "2020-09-08 17:48:44 INFO: setting ignored attribute vectors_norm to None\n",
      "2020-09-08 17:48:44 INFO: loading vocabulary recursively from ../tmp_data/word2vec.d300.sg.w5.model.vocabulary.* with mmap=None\n",
      "2020-09-08 17:48:44 INFO: loading trainables recursively from ../tmp_data/word2vec.d300.sg.w5.model.trainables.* with mmap=None\n",
      "2020-09-08 17:48:44 INFO: setting ignored attribute cum_table to None\n",
      "2020-09-08 17:48:44 INFO: loaded ../tmp_data/word2vec.d300.sg.w5.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6978, 300)\n"
     ]
    }
   ],
   "source": [
    "vectorPath = '../tmp_data/word2vec.d300.sg.w5.model' # 本地词向量的地址\n",
    "Word2VecModel = gensim.models.Word2Vec.load(vectorPath) # 读取词向量\n",
    "\n",
    "embeddings_matrix = np.zeros((len(vocab) + 1, Word2VecModel.vector_size))\n",
    "print(embeddings_matrix.shape)\n",
    "for word, index in vocab.items():\n",
    "    if word in Word2VecModel.wv.vocab.keys():\n",
    "        embeddings_matrix[index] = Word2VecModel.wv[word]  # 词向量矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/cut_test_b.csv', sep='\\t')\n",
    "x_test_word_ids = tokenizer.texts_to_sequences(test_df['cut_text'])\n",
    "x_test_padded_seqs = pad_sequences(x_test_word_ids, maxlen=max_len, padding=\"post\", truncating=\"post\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(max_len, embeddings_matrix):\n",
    "    main_input = Input(shape=(max_len,), dtype='float64')\n",
    "\n",
    "    # 嵌入层（使用预训练的词向量）\n",
    "    embedder = Embedding(input_dim = len(embeddings_matrix), output_dim = embeddings_matrix.shape[1], weights=[embeddings_matrix], input_length=max_len, trainable=False)\n",
    "    embed = embedder(main_input)\n",
    "    \n",
    "    # 卷积层和池化层，设置卷积核大小分别为3,4,5,6\n",
    "    cnn1 = Conv1D(256, 3, padding='same', strides=1, activation='relu')(embed)\n",
    "    max1 = MaxPooling1D(pool_size=max_len)(cnn1)\n",
    "#     ave1 = AveragePooling1D(pool_size=max_len)(cnn1)\n",
    "    cnn2 = Conv1D(256, 4, padding='same', strides=1, activation='relu')(embed)\n",
    "    max2 = MaxPooling1D(pool_size=max_len)(cnn2)\n",
    "#     ave2 = AveragePooling1D(pool_size=max_len)(cnn2)\n",
    "    cnn3 = Conv1D(256, 5, padding='same', strides=1, activation='relu')(embed)\n",
    "    max3 = MaxPooling1D(pool_size=max_len)(cnn3)\n",
    "#     ave3 = AveragePooling1D(pool_size=max_len)(cnn3)\n",
    "    cnn4 = Conv1D(256, 10, padding='same', strides=1, activation='relu')(embed)\n",
    "    max4 = MaxPooling1D(pool_size=max_len)(cnn4)\n",
    "#     ave4 = AveragePooling1D(pool_size=max_len)(cnn4)\n",
    "#     cnn = concatenate(axis=-1)([max1, ave1, max2, ave2, max3, ave3, max4, ave4])\n",
    "    cnn = concatenate(axis=-1)([max1, max2, max3, max4])\n",
    "    flat = Flatten()(cnn)\n",
    "    drop = Dropout(0.2)(flat)\n",
    "    main_output = Dense(14, activation='softmax')(drop)\n",
    "    model = Model(inputs=main_input, outputs=main_output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 81s 2ms/sample\n",
      "50000/50000 [==============================] - 74s 1ms/sample\n",
      "50000/50000 [==============================] - 74s 1ms/sample\n",
      "50000/50000 [==============================] - 74s 1ms/sample\n",
      "50000/50000 [==============================] - 74s 1ms/sample\n"
     ]
    }
   ],
   "source": [
    "# use checkpoint\n",
    "test_pred = np.zeros((len(test_df), 14))\n",
    "for idx in range(5):\n",
    "    model = build_model(max_len, embeddings_matrix)\n",
    "    model_path = '../models/textcnn_maxlen3000_tpre1500_tpost1500_ppost_{}.h5'.format(idx+1)\n",
    "    model.load_weights(model_path)\n",
    "    prob = model.predict(x_test_padded_seqs, batch_size=256, verbose=1)\n",
    "    test_pred += prob / 5\n",
    "#     print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = np.argmax(test_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label'] = predict_label\n",
    "test_df.to_csv(\"../results/textcnn_maxlen3000_tpre1500_tpost1500_ppost_+f20_5fold_test_b.csv\", index=False, columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = train_df[train_df['label'] != train_df['predict_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1[temp1['predict_prob'] < 0.5]['label'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = temp1.apply(lambda x:\"{0}_{1}\".format(x['label'],x['predict_label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda x, y: x if x>y else y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test = [(1,)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
